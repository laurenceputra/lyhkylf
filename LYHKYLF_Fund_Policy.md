# LYHKYLF Fund Policy (v0.2)

This document defines the operating policy for the fund: scope, eligibility, decision rules, measurement, safeguarding, data dignity, publication, and handoff expectations.

---

## 1) Purpose

Seed early-stage, high-learning experiments that expand **youth agency and capabilities** for **low-income youth (7–18) in Singapore**, with a clear pathway to **institutional handoff within ~3 years**.

---

## 2) Target population and eligibility

### 2.1 Geography and age
- **Singapore only**
- **Age:** 7–18 years old (inclusive)

### 2.2 Low-income eligibility (default rule)
A youth is considered eligible if they meet **any** of the following (documented per grant):
- Covered by **most general means-tested schemes** in Singapore (broadly inclusive).
- Recipient of support from **IPC charities** (generally qualifies).
- Lives in **1-room or 2-room flats**.

**Exceptions:** Handled **case-by-case** when needed; grantee must document the rationale and approach.

---

## 3) Program scope

### 3.1 In scope
- **Direct-to-youth delivery only** (youth are the primary participants and beneficiaries during the grant period).
- School-adjacent enrichment (after-school, weekends, holidays) that increases:
  - **Agency:** choice-making, self-efficacy, creative production
  - **Capabilities (priority):** learning, creativity  
  - **Health-functioning:** **case-by-case, low priority** (only when the theory of change is strong; no treatment)
- **High-learning experiments** (high-risk or medium-risk); **no replication-only** funding.

### 3.2 Out of scope (hard exclusions)
- Programs without youth delivery during the grant period (e.g., adult-only training, tool-building/curriculum creation with no youth delivery).
- Policy advocacy and movement-building.
- For-profit entities as primary grantees; individuals (no scholarships/stipends to individuals).
- Regranting/intermediary models.
- **Mental health crisis** work.
- **Medication-adjacent** work.
- Health treatment/clinical services.

---

## 4) Minimum bar (direct-to-youth)

- **Cohort minimum:** ≥ **5 youth**
- **Dosage minimum:** ≥ **15 sessions per year** with the youth
- **One-off holiday camps:** only under **personal discretion**.

---

## 5) Grant parameters

- **Grant size:** SGD **10k–30k per year**
- **Duration:** annual grants, renewable up to ~**3 years**
- **Checkpoints:** Months **6**, **12**, **24** (renew / pivot / stop / graduate)

---

## 6) Outcomes and measurement

### 6.1 Required primaries (locked by Month 6)
By **Month 6**, every grant must define and lock **two primaries**:

1) **Primary Outcome (Trajectory Lever)**  
Choose **one** primary outcome from the fund’s **Trajectory Lever Menu** (6.2), with guardrails in 6.3.

2) **Primary Mechanism Indicator (Proximal)**  
Define **one** mechanism indicator that represents the earliest observable proof that the theory of change is firing (e.g., a short rubric, artifact score, or behavioral proxy).

Programs may start Months 0–6 with exploratory measures, but both primaries must be set by Month 6 for renewal decisions at Months 12 and 24.

### 6.2 Trajectory Lever Menu (choose one as the Primary Outcome)
The fund’s default menu includes:

- **Sustained engagement / persistence** (behavioral/admin)
- **Skill / mastery progression** (domain-specific; ideally anchored in observable progression)
- **Self-regulation / executive function** (behavioral/rubric)
- **Belonging / social connectedness** (often mixed-method; should include a behavioral/admin anchor)
- **Autonomy / choice competence** (rubric + behavioral anchor)
- **Wellbeing / functioning** *(case-by-case; low priority; non-clinical only)*

The fund may refine the menu per thematic cycle.

### 6.3 Guardrails to keep outcomes decision-grade
For the **Primary Outcome (Trajectory Lever)**:

- **Behavioral/admin anchor required:** the primary must be behavioral/admin **or** be anchored to a behavioral/admin proxy (e.g., attendance continuity, practice hours, progression level).
- **Durability definition required:** the primary must specify durability, such as:
  - sustained for **>= 8 weeks**, and/or
  - repeated across **>= 2 cycles/cohorts by Month 24** (or an equivalent repetition standard).
- **Unit + cadence required:** the primary must specify unit of analysis (youth-level internally; **aggregate reporting to the fund**) and measurement cadence.

### 6.4 Acceptable instruments and evidence design
**Instruments allowed** (as appropriate to the lever/mechanism):
- Observed rubrics
- Artifact-based scoring (outputs/portfolios)
- Anonymous, age-appropriate self-report
- External signals (teacher/mentor ratings) where feasible and appropriate
- Behavioral/admin data (attendance, continuity, practice hours, progression)

**Comparison designs (preferred set):**
- **Matched comparison**, and/or
- **Within-cohort stepped rollout**.

Where comparisons are not feasible, grantees must justify and strengthen pre/post + mechanism evidence.

### 6.5 Stage expectations (Month 6 / 12 / 24)
- **Month 6 (baseline + mechanism):**
  - Both primaries locked (Outcome lever + Mechanism indicator)
  - Baseline established
  - Early movement in the mechanism indicator (or a clear plan to detect it by Month 12)

- **Month 12 (benefit signals):**
  - Pre/post movement on the **Primary Outcome**
  - Evidence that mechanism movement plausibly links to the outcome
  - Comparison evidence where feasible

- **Month 24 (durability + repeatability):**
  - Outcome durability achieved per definition
  - Positive signals across **>= 2 cohorts/cycles** where applicable
  - Handoff-ready evidence snapshot aligned to the handoff lane

### 6.6 Minimum required indicators (all grants)
All grants must report:
- Attendance / dosage
- Retention / completion
- Safeguarding incidents and resolution timeliness

### 6.7 Measurement burden and data dignity
- Measurement burden should remain within **~20%** of the grant resources (exceptions require written justification).
- Data collection is minimal; identifiers limited to **name and phone number** for operations.
- Grantees may use participant IDs internally, but the fund receives **aggregate reporting only**.
- Raw data retained up to **12 months after program end**; aggregated data may be retained longer.


## 7) Stage gates and renewal decisions

### 7.1 Decision points
At Months **6**, **12**, **24** the fund decides:
- **Renew** (optionally with conditions)
- **Pivot** (as a renewal condition)
- **Stop**
- **Graduate** (handoff-ready / final-year transition)

### 7.2 Missing data but strong delivery
If delivery is strong but measurement is inadequate, the fund may extend runway **tied to the program’s cycle cadence** to improve measurement.

### 7.3 Flat outcomes but strong delivery
Default action: **Renew with conditions** (tightened hypothesis + redesigned delivery).

### 7.4 Decision memos
- **Charity/grantee writes** Month 6/12/24 learning and results memos.
- **Grant panel reviews** and recommends.
- **Anchor donor decides** (final approval).

---

## 8) Safeguarding

### 8.1 Minimum safeguarding standard
Required at minimum: **Baseline + screening**, with an expectation to move toward **full** standard over time.

- **Baseline (minimum):**
  - Child protection policy
  - Mandatory reporting SOP
  - Incident logging + escalation workflow
  - Staff/volunteer training
- **Screening (minimum):**
  - Background checks for staff/volunteers where applicable
  - Code of conduct
  - Safe supervision practices
- **Aim for full (target standard):**
  - Photography/media consent rules
  - Transport rules
  - Partner venue safety checklist
  - Safe recruitment process
  - Regular refreshers/drills and documentation

### 8.2 Supervision ratios and adequacy review
- Ratios/supervision rules are set by the **grantee’s safeguarding policy**.
- The fund reviews adequacy as part of diligence and renewal.

### 8.3 Outdoor / physical-risk programs (allowed with strict controls)
Outdoor/high-physical-risk programs may be funded **only with strict risk controls**, including:
- Certified instructors (where relevant)
- Appropriate insurance coverage
- Venue/activity risk assessment
- Emergency response plan
- **Explicit parental consent**
- **Transport rules**
- **Minimum supervision standards** (even if exact ratios remain grantee-defined)

### 8.4 Auto-stop rule for high-risk incidents
Stop funding when an **unresolved high-risk incident persists beyond 7 days**.

### 8.5 Mandatory reporting
Mandatory reporting is required.

---

## 9) Data dignity and PDPA

### 9.1 Collection limits
- The fund’s posture is **minimal data collection**.
- **Direct identifiers collected should be limited to name and phone number** for operational purposes.
- No collection of sensitive health/clinical data (consistent with out-of-scope).

### 9.2 Reporting to the fund
- Fund receives **aggregate reporting only**.
- Grantees may use participant IDs internally for measurement and operations, but must keep identity mapping controlled and minimized.

### 9.3 Retention
- **Raw data:** retain max **12 months after the program ends**, then delete.
- **Aggregated data:** may be retained **indefinitely**.

### 9.4 Consent
Consent is embedded in enrollment, with **explicit opt-out for non-essential measurement**.

---

## 10) Budget policy

### 10.1 Overhead cap
- **Hard cap: 20%** of the grant budget.

### 10.2 Allowable costs (case-by-case posture within scope)
Allowable costs are assessed **case-by-case** (must be well-justified and aligned to delivery/learning), including:
- Program delivery (facilitators, materials, venue)
- Transport/meals/access supports
- Devices/tools and insurance
- Safeguarding and PDPA compliance costs
- External evaluation support (subject to the M&E burden cap)

---

## 11) For-profit involvement (vendor model only)

- Subcontracting to a for-profit is **allowed** only as a **service provider model** (primary grantee must be a charity).
- **Pass-through is not allowed:** a charity cannot be used as a wrapper for mostly for-profit delivery/control.

---

## 12) Publication and transparency

### 12.1 Annual publication minimum
Each active grant must publish learnings at least **once per year** (anonymized as appropriate).

### 12.2 Publication formats
- Ongoing short-form posts **and**
- Annual synthesis (e.g., PDF compendium)

### 12.3 Expanded learning template (required contents)
Each annual write-up must include:
- Hypothesis and theory of change (mechanism)
- Cohort definition, recruitment funnel, and dosage
- Retention/completion and reasons for drop-off
- Outcomes and results (including comparison logic when applicable)
- Unit economics: cost per youth per cycle; cost-down levers and progress
- Safeguarding incidents (if any) and resolution learnings
- Implementation pitfalls and changes made
- Failure analysis (what did not work and why)
- Handoff readiness status and next steps

### 12.4 Exceptions
Publication exceptions are **case-by-case** (e.g., legal/safety risks), with panel recommendation and anchor decision.

---

## 13) Handoff within ~3 years

### 13.1 Lane selection
By **Month 12**, each grant must specify a **handoff lane** (set per grant).

### 13.2 Month 24 “handoff-ready” minimum (light pack)
By Month 24, the grantee should be able to provide a light handoff package:
- Program playbook (what is delivered and how)
- Unit economics summary
- Evidence snapshot (outcomes + implementation learnings)

### 13.3 Fund role
The fund provides **active co-development from Month 12** (help shaping the handoff lane, evidence narrative, and package).

---

## 14) Portfolio strategy and pipeline

- Active grants/year: **3–5**
- Strategy: **thematic cycles**
- Concentration limits: **none**
- Pipeline: **hybrid** (scout + open call)
- Diligence: **standard**
- Renewals vs new bets: **50/50** (portfolio-level target)

---

## 15) Governance and conflicts of interest

### 15.1 Decision rights
- Anchor donor retains **final grant-approval authority** and renewal/stop/graduation authority.
- Grant panel provides discussion and recommendation.

### 15.2 Conflicts of interest (recusal)
- Recusal required for **recent ties (lookback: 12 months)** and **close personal relationships**.
- Recusal scope: **discussion + vote**.

---

## Appendix A: Required “Learning Brief” at award (one-pager)

Each grant must provide a one-page brief covering:
- Problem and target cohort (incl. low-income definition used)
- Theory of change (mechanism)
- Delivery plan and dosage
- **Primary Outcome (Trajectory Lever)** chosen from the menu + **durability definition**
- **Primary Mechanism Indicator (Proximal)** and why it should move early
- Hypotheses: adoption, cost curve, safeguarding
- Measurement plan (<=20% burden) + comparison design intent (matched comparison and/or within-cohort stepped rollout where feasible)
- Month 6 targets (provisional)
- Risks and mitigations (incl. safeguarding/data)

---

## Appendix B: Case-by-case decisions and escalation

The following are handled **case-by-case**:
- Health-functioning scope (low priority)
- Budget line items (within scope)
- Publication exceptions

Process:
- **Grant panel recommends**
- **Anchor donor decides**

---

## Appendix C: Trajectory Lever Definitions and Default Metrics (Starter Set)

This appendix is a practical starter set to help grantees select a **Primary Outcome (Trajectory Lever)** quickly. Grantees may adapt these to context, but must preserve:
- a **behavioral/admin anchor**, and
- a **durability definition**.

### C1) Sustained engagement / persistence (behavioral/admin)
**Definition:** Continued participation and re-engagement over time in the target activity.  
**Default metrics (pick 1–2):**
- Continuity months (months active without dropping out)
- Attendance continuity (e.g., % weeks attended; streaks; gap frequency)
- Practice hours (tracked hours per week/month)
- Re-enrolment rate into next cycle  
**Durability defaults:** sustained >= 8 weeks; and/or repeated across >= 2 cycles by Month 24.

### C2) Skill / mastery progression (domain-specific)
**Definition:** Observable progression in a defined skill pathway.  
**Default metrics (pick 1–2):**
- Progression level attained (e.g., levels/badges/modules completed)
- Competency rubric score (pre/post on a small rubric)
- Portfolio/output quality progression (scored artifacts over time)
- Task difficulty progression (youth completes increasingly difficult tasks)  
**Behavioral/admin anchors:** level advancement; module completion; artifact completion counts.  
**Durability defaults:** progression sustained across >= 8 weeks; and/or replicated across >= 2 cycles by Month 24.

### C3) Self-regulation / executive function (behavioral/rubric)
**Definition:** Improved planning, follow-through, and regulation in the context of program tasks.  
**Default metrics (pick 1–2):**
- Planning/follow-through rubric (mentor/facilitator rated)
- Task completion under challenge (completion of “hard tasks” or persistence tasks)
- On-time completion rate for assigned practice/tasks
- Goal-setting and review cycles completed (count of completed cycles)  
**Behavioral/admin anchors:** completion rates; on-time rates; cycle counts.  
**Durability defaults:** sustained >= 8 weeks; and/or repeated across >= 2 cycles by Month 24.

### C4) Belonging / social connectedness
**Definition:** Increased sense of belonging and constructive participation in a community.  
**Default metrics (pick 1–2):**
- Anonymous belonging/self-reported connectedness (short, age-appropriate scale)
- Participation in group activities (admin counts; contributions/roles taken)
- Peer network engagement (e.g., number of sessions with active collaboration)
- Group contribution rubric (facilitator rated; anchored to observable behaviors)  
**Behavioral/admin anchors:** participation counts; role-taking counts; collaboration session counts.  
**Durability defaults:** sustained >= 8 weeks; and/or repeated across >= 2 cycles by Month 24.

### C5) Autonomy / choice competence
**Definition:** Improved ability to make and execute meaningful choices, including adaptation after mismatch.  
**Default metrics (pick 1–2):**
- “Quality of choice cycle” rubric (initiate -> articulate reasons -> execute -> reflect/adapt)
- Number of self-initiated choices/actions (admin counts)
- Follow-through rate on chosen plan (completion/attendance for chosen activity)
- Adaptation after mismatch (documented switch with reflection)  
**Behavioral/admin anchors:** follow-through rates; count of initiated choices; completion of choice cycles.  
**Durability defaults:** sustained >= 8 weeks; and/or repeated across >= 2 cycles by Month 24.

### C6) Wellbeing / functioning (case-by-case; low priority; non-clinical)
**Definition:** Non-clinical functioning improvements that enable participation (no treatment/clinical services).  
**Default metrics (pick 1–2):**
- Attendance/participation enabled by functioning (admin continuity)
- Simple functioning checklist (non-sensitive; aligned to program context)
- Caregiver/mentor-rated functioning rubric (non-clinical, minimal)  
**Behavioral/admin anchors:** participation continuity; reduction in missed sessions due to functioning-related barriers (if tracked non-sensitively).  
**Durability defaults:** sustained >= 8 weeks; and/or repeated across >= 2 cycles by Month 24.

### C7) Mechanism Indicator examples (for the required Primary Mechanism Indicator)
Mechanism indicators should be the earliest observable proof that the theory of change is firing. Examples:
- Short rubric that scores a key behavior (e.g., “choice cycle quality”, “practice habit formation”, “mentor-youth session quality” with observable anchors)
- Artifact-based early outputs (e.g., first completed project; early portfolio milestones)
- Behavioral proxy that precedes the main outcome (e.g., week-2 re-attendance, first 3-week streak, first level completion)

Mechanism indicators should be:
- lightweight to collect,
- clearly linked to the primary outcome, and
- detectable by Month 6–12.

